{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "\n",
    "import inflection\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos dados de produção e dados das lojas\n",
    "df_production   = pd.read_csv( '../data/production.csv', low_memory=False )\n",
    "df_store        = pd.read_csv( '../data/store.csv', low_memory=False )\n",
    "\n",
    "df_00           = pd.merge( df_production, df_store, how='left', on='Store' )\n",
    "\n",
    "# Importação do modelo treinado\n",
    "model_xgb       = pickle.load(open( '../exports/cicle_products/model_xgb.pkl', 'rb'))\n",
    "\n",
    "# Importação de scalers e encoders\n",
    "rs_competition_distance     = pickle.load(open( '../exports/cicle_products/rs_competition_distance.pkl', 'rb'))\n",
    "rs_competition_time_month   = pickle.load(open( '../exports/cicle_products/rs_competition_time_month.pkl', 'rb'))\n",
    "mms_promo_time_week         = pickle.load(open( '../exports/cicle_products/mms_promo_time_week.pkl', 'rb'))\n",
    "mms_year                    = pickle.load(open( '../exports/cicle_products/mms_year.pkl', 'rb'))\n",
    "le_store_type               = pickle.load(open( '../exports/cicle_products/le_store_type.pkl', 'rb'))\n",
    "ohe_state_holiday           = pickle.load(open( '../exports/cicle_products/ohe_state_holiday.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = df_00.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ohe(encoder ,encoded_array, variable_name, df):\n",
    "    '''\n",
    "    Aplica o One Hot Encoder no dataframe, criando as colunas respectivas às categorias no encoder e elimininado a coluna original.\n",
    "\n",
    "    Parâmetros:\n",
    "        encoder (OneHotEncoder): Encoder OneHotEncoder do Scikit-learn pré-configurado.\n",
    "        encoded_array (ndarray): Array gerado pelo OneHotEncoder.\n",
    "        variable_name (str): Nome da variável original.\n",
    "        df (DataFrame): Dataframe a ser alterado.\n",
    "\n",
    "    Retorna:\n",
    "        Um novo dataframe com as novas colunas respectivas às categorias no encoder e sem a coluna original.\n",
    "    '''\n",
    "\n",
    "    # Criar DataFrame com nomes corretos\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array,\n",
    "        columns=encoder.get_feature_names_out([variable_name]),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    # Concatenar com o DataFrame original, removendo a coluna original\n",
    "    df_f = pd.concat([df.drop(columns=[variable_name]), encoded_df], axis=1)\n",
    "\n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0. Simulação de produção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1. Funções de transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções para aplicação de todas as transformações de dados realizadas durante o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_01 (df):\n",
    "    df_01 = df.copy()\n",
    "\n",
    "    # Renomeando colunas:\n",
    "    cols_old = ['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday',\n",
    "                'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
    "                'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
    "                'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "    snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "    cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "    df_01.columns = cols_new\n",
    "\n",
    "\n",
    "    # Transformando variável 'date' em datetime:\n",
    "    df_01['date'] = pd.to_datetime( df_01['date'] )\n",
    "\n",
    "\n",
    "    # Preenchendo dados vazios\n",
    "\n",
    "    #competition_distance - Transforma os Nan em 200000 (muito maior do que a maior distância máxima no banco de dados):     \n",
    "    df_01['competition_distance'] = df_01['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "\n",
    "    #competition_open_since_month - Caso seja NA, extrai o mês da coluna 'date':\n",
    "    df_01['competition_open_since_month'] = df_01.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "    #competition_open_since_year - Caso seja NA, extrai o ano da coluna 'date':\n",
    "    df_01['competition_open_since_year'] = df_01.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "    #promo2_since_week - Caso seja NA, extrai a semana da coluna 'date':           \n",
    "    df_01['promo2_since_week'] = df_01.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "    #promo2_since_year - Caso seja NA, extrai o ano da coluna 'date':           \n",
    "    df_01['promo2_since_year'] = df_01.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "    #promo_interval - Cria uma coluna 'is_promo' para indicar se está dentro do período de promoção ou não.           \n",
    "    month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'} # Cria o mapa de meses\n",
    "\n",
    "    df_01['promo_interval'].fillna(0, inplace=True ) # Transforma Nan em 0\n",
    "\n",
    "    df_01['month_map'] = df_01['date'].dt.month.map( month_map ) # Extrai o mês de 'date' e transforama em letras conforme o mapa\n",
    "\n",
    "    # Checa se o mês de 'month_map' está contido nos meses de 'promo_interval' e se estiver muda para 1 o valor de 'is_promo' indicando que está no período de promoção\n",
    "    df_01['is_promo'] = df_01[['promo_interval', 'month_map']].apply(\n",
    "                                                                    lambda x: \n",
    "                                                                    0 if x['promo_interval'] == 0 \n",
    "                                                                    else 1 if x['month_map'] in x['promo_interval'].split( ',' ) \n",
    "                                                                    else 0, axis=1 \n",
    "                                                                    )\n",
    "\n",
    "\n",
    "    # Alterando tipagem de dados\n",
    "\n",
    "    # competiton\n",
    "    df_01['competition_open_since_month'] = df_01['competition_open_since_month'].astype( int )\n",
    "    df_01['competition_open_since_year'] = df_01['competition_open_since_year'].astype( int )\n",
    "        \n",
    "    # promo2\n",
    "    df_01['promo2_since_week'] = df_01['promo2_since_week'].astype( int )\n",
    "    df_01['promo2_since_year'] = df_01['promo2_since_year'].astype( int )\n",
    "\n",
    "    return df_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_02 (df):\n",
    "    df_02 = df.copy()\n",
    "\n",
    "    # Criando variáveis derivadas\n",
    "\n",
    "    # year - Nova coluna apenas com o ano da coluna 'date'\n",
    "    df_02['year'] = df_02['date'].dt.year\n",
    "    df_02['year'] = np.int64(df_02['year'])\n",
    "\n",
    "    # month - Nova coluna apenas com o mês da coluna 'date'\n",
    "    df_02['month'] = df_02['date'].dt.month\n",
    "    df_02['month'] = np.int64(df_02['month'])\n",
    "\n",
    "    # day - Nova coluna apenas com o dia da coluna 'date'\n",
    "    df_02['day'] = df_02['date'].dt.day\n",
    "    df_02['day'] = np.int64(df_02['day'])\n",
    "\n",
    "    # week of year - Nova coluna apenas com a semana do ano da coluna 'date'\n",
    "    df_02['week_of_year'] = df_02['date'].dt.strftime('%W')\n",
    "    df_02['week_of_year'] = df_02['week_of_year'].astype( int )\n",
    "\n",
    "    # year week - Nova coluna apenas com semana do ano e o ano da coluna 'date'\n",
    "    df_02['year_week'] = df_02['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "    # competition since - Converte 'competition_open_since_year' e 'competition_open_since_month' em uma variável com o tempo de existência do concorrente em meses. \n",
    "    df_02['competition_since'] = df_02.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "    df_02['competition_time_month'] = ( ( df_02['date'] - df_02['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "    # promo since - Converte 'promo2_since_year' e 'promo2_since_week' em uma variável com o tempo de promoção em semanas. \n",
    "    df_02['promo_since'] = df_02['promo2_since_year'].astype( str ) + '-' + df_02['promo2_since_week'].astype( str )\n",
    "    df_02['promo_since'] = df_02['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "    df_02['promo_time_week'] = ( ( df_02['date'] - df_02['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "    # assortment\n",
    "    df_02['assortment'] = df_02['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "    # state holiday\n",
    "    df_02['state_holiday'] = df_02['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "    return df_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_03 (df):\n",
    "    df_03 = df.copy()\n",
    "\n",
    "    # Filtrando linhas apenas para dias em que houve vendas:\n",
    "    df_03 = df_03[(df_03['open'] != 0)]\n",
    "\n",
    "\n",
    "    # Removendo colunas:\n",
    "    cols_drop = ['open', 'competition_open_since_year', 'competition_open_since_month', 'promo2_since_year', 'promo2_since_week', 'promo_interval', 'month_map']\n",
    "    df_03 = df_03.drop( cols_drop, axis=1 )\n",
    "\n",
    "    return df_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_05(df):\n",
    "    df_05 = df.copy()\n",
    "\n",
    "    # Normalização - Não há dados\n",
    "\n",
    "\n",
    "    # Rescaling\n",
    "\n",
    "    # competition_distance\n",
    "    df_05['competition_distance'] = rs_competition_distance.transform( df_05[['competition_distance']].values )\n",
    "\n",
    "    # competition_time_month\n",
    "    df_05['competition_time_month'] = rs_competition_time_month.transform( df_05[['competition_time_month']].values )\n",
    "\n",
    "    # promo_time_week\n",
    "    df_05['promo_time_week'] = mms_promo_time_week.transform( df_05[['promo_time_week']].values )\n",
    "\n",
    "    # year\n",
    "    df_05['year'] = mms_year.transform( df_05[['year']].values )\n",
    "\n",
    "\n",
    "    # Encoding\n",
    "\n",
    "    # state_holiday - One Hot Encoding\n",
    "    encoded_array = ohe_state_holiday.transform(df_05[['state_holiday']])\n",
    "    df_05 = apply_ohe(ohe_state_holiday, encoded_array, 'state_holiday', df_05)\n",
    "\n",
    "    # store_type - Label Encoding\n",
    "    df_05['store_type'] = le_store_type.transform( df_05[['store_type']].values )\n",
    "\n",
    "    # assortment - Ordinal Encoding\n",
    "    assortment_dict = {'basic': 1,  'extra': 2, 'extended': 3}\n",
    "    df_05['assortment'] = df_05['assortment'].map( assortment_dict )\n",
    "\n",
    "\n",
    "    # Transformação de natureza (encoder cíclico)\n",
    "\n",
    "    # day of week\n",
    "    df_05['day_of_week_sin'] = df_05['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "    df_05['day_of_week_cos'] = df_05['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "    # month\n",
    "    df_05['month_sin'] = df_05['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "    df_05['month_cos'] = df_05['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "    # day \n",
    "    df_05['day_sin'] = df_05['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "    df_05['day_cos'] = df_05['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "    # week of year\n",
    "    df_05['week_of_year_sin'] = df_05['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "    df_05['week_of_year_cos'] = df_05['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )\n",
    "\n",
    "\n",
    "    # Descartando colunas antigas\n",
    "\n",
    "    cols_drop = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
    "    df_05 = df_05.drop( cols_drop, axis=1 )\n",
    "\n",
    "    return df_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_06 (df):\n",
    "    df_06 = df.copy()\n",
    "\n",
    "    cols_selected_boruta = [\n",
    "                            'id', # Para manter o registro, será descartada antes da aplicação do modelo\n",
    "                            'store',\n",
    "                            'promo',\n",
    "                            'store_type',\n",
    "                            'assortment',\n",
    "                            'competition_distance',\n",
    "                            'promo2',\n",
    "                            'competition_time_month',\n",
    "                            'promo_time_week',\n",
    "                            'day_of_week_sin',\n",
    "                            'day_of_week_cos',\n",
    "                            'month_sin', # O algoritmo tinha descartado a variável 'month_sin', mas como ela é componente da variável 'month_cos' então manteremos ela no conjunto de dados.\n",
    "                            'month_cos',\n",
    "                            'day_sin',\n",
    "                            'day_cos'\n",
    "                            ]\n",
    "\n",
    "    df_06 = df_06[ cols_selected_boruta ]\n",
    "\n",
    "    return df_06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Aplicação das transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = apply_01(df_10)\n",
    "df_10 = apply_02(df_10)\n",
    "df_10 = apply_03(df_10)\n",
    "df_10 = apply_05(df_10)\n",
    "df_10 = apply_06(df_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3. Realizando previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando previsões (sem a coluna de id)\n",
    "pred = model_xgb.predict(df_10.drop(['id'], axis=1))\n",
    "\n",
    "# Anexando previsões ao dataframe\n",
    "df_10['predictions'] = np.expm1( pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anexando previsões ao dataframe original\n",
    "\n",
    "# Procurando previsões em df_10 e aplicando em df_00 com base no id\n",
    "pred_map = df_10.set_index('id')['predictions']\n",
    "df_00['predictions'] = df_00['Id'].map(pred_map)\n",
    "\n",
    "# Preenchendo previsões faltantes com zeros\n",
    "df_00['predictions'] = df_00['predictions'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4. Previsões por loja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predictions",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8f43ec60-5c34-4b83-967d-8da312cb5af2",
       "rows": [
        [
         "0",
         "1",
         "$ 177,773.34"
        ],
        [
         "1",
         "3",
         "$ 274,382.12"
        ],
        [
         "2",
         "7",
         "$ 375,512.44"
        ],
        [
         "3",
         "8",
         "$ 224,200.17"
        ],
        [
         "4",
         "9",
         "$ 275,661.25"
        ],
        [
         "5",
         "10",
         "$ 215,574.94"
        ],
        [
         "6",
         "11",
         "$ 297,298.66"
        ],
        [
         "7",
         "12",
         "$ 285,366.75"
        ],
        [
         "8",
         "13",
         "$ 187,543.44"
        ],
        [
         "9",
         "14",
         "$ 210,022.42"
        ],
        [
         "10",
         "15",
         "$ 276,045.81"
        ],
        [
         "11",
         "16",
         "$ 300,522.44"
        ],
        [
         "12",
         "19",
         "$ 266,286.72"
        ],
        [
         "13",
         "20",
         "$ 277,778.34"
        ],
        [
         "14",
         "21",
         "$ 209,487.25"
        ],
        [
         "15",
         "22",
         "$ 177,176.09"
        ],
        [
         "16",
         "23",
         "$ 291,786.78"
        ],
        [
         "17",
         "24",
         "$ 340,455.66"
        ],
        [
         "18",
         "25",
         "$ 414,489.22"
        ],
        [
         "19",
         "27",
         "$ 351,013.03"
        ],
        [
         "20",
         "29",
         "$ 284,471.56"
        ],
        [
         "21",
         "30",
         "$ 213,744.31"
        ],
        [
         "22",
         "31",
         "$ 241,430.17"
        ],
        [
         "23",
         "32",
         "$ 152,042.77"
        ],
        [
         "24",
         "33",
         "$ 332,743.25"
        ],
        [
         "25",
         "35",
         "$ 361,929.28"
        ],
        [
         "26",
         "36",
         "$ 345,748.53"
        ],
        [
         "27",
         "38",
         "$ 229,528.77"
        ],
        [
         "28",
         "39",
         "$ 237,826.72"
        ],
        [
         "29",
         "40",
         "$ 173,941.97"
        ],
        [
         "30",
         "41",
         "$ 253,663.73"
        ],
        [
         "31",
         "42",
         "$ 401,587.19"
        ],
        [
         "32",
         "43",
         "$ 248,943.22"
        ],
        [
         "33",
         "45",
         "$ 195,560.31"
        ],
        [
         "34",
         "46",
         "$ 198,614.78"
        ],
        [
         "35",
         "47",
         "$ 306,717.44"
        ],
        [
         "36",
         "48",
         "$ 153,445.20"
        ],
        [
         "37",
         "49",
         "$ 298,438.25"
        ],
        [
         "38",
         "50",
         "$ 173,209.25"
        ],
        [
         "39",
         "51",
         "$ 276,545.19"
        ],
        [
         "40",
         "52",
         "$ 253,050.22"
        ],
        [
         "41",
         "53",
         "$ 212,644.36"
        ],
        [
         "42",
         "56",
         "$ 300,538.25"
        ],
        [
         "43",
         "58",
         "$ 257,172.03"
        ],
        [
         "44",
         "61",
         "$ 202,721.83"
        ],
        [
         "45",
         "62",
         "$ 250,729.08"
        ],
        [
         "46",
         "63",
         "$ 270,060.47"
        ],
        [
         "47",
         "64",
         "$ 415,869.25"
        ],
        [
         "48",
         "66",
         "$ 239,321.56"
        ],
        [
         "49",
         "67",
         "$ 314,051.56"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 856
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>$ 177,773.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>$ 274,382.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>$ 375,512.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>$ 224,200.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>$ 275,661.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1111</td>\n",
       "      <td>$ 201,693.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>1112</td>\n",
       "      <td>$ 351,944.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>1113</td>\n",
       "      <td>$ 267,469.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>1114</td>\n",
       "      <td>$ 844,619.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>1115</td>\n",
       "      <td>$ 276,246.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store   predictions\n",
       "0        1  $ 177,773.34\n",
       "1        3  $ 274,382.12\n",
       "2        7  $ 375,512.44\n",
       "3        8  $ 224,200.17\n",
       "4        9  $ 275,661.25\n",
       "..     ...           ...\n",
       "851   1111  $ 201,693.61\n",
       "852   1112  $ 351,944.00\n",
       "853   1113  $ 267,469.78\n",
       "854   1114  $ 844,619.12\n",
       "855   1115  $ 276,246.28\n",
       "\n",
       "[856 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux = df_00[['Store', 'predictions']].groupby( 'Store' ).sum().reset_index()\n",
    "df_aux['predictions'] = df_aux['predictions'].map( '$ {:,.2f}'.format )\n",
    "df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5. Previsão Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 231,183,632.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"$ {df_00['predictions'].sum():,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
